\chapter{Approach}\label{chap:approach}
To semantically segment urban scenes and extract predictions for curbs and curb cuts, we proposed to use a deep neural network based on the DeepLab v3+ architecture with a loss function inspired by "U-Net: Convolutional Networks for Biomedical Image Segmentation" by Olaf Ronneberger et al.~\cite{unet}.
In this chapter, the architecture used and an explanation of our loss function will be discussed.

\section{Architecture Selection} \label{section:approach-architectureselection}
We came to use the DeepLab v3+ architecture after running these experiments due to significantly outperforming the other networks. A further discussion of the results can be found in section \ref{section:experiments-networkevaluation}.

\subsection{Network Architecture}\label{section:approach-networkarchitecture}
We propose to apply the DeepLab v3+ architecture to our stated problem of curb and curb cut segmentation.
The architecture itself is given in \figref{fig:approach-network} with further descriptions in Tables \ref{tab:drn}-\ref{tab:decoder}\footnote{The full implementation written using the PyTorch framework can be found at \url{github.com/yvan674/CurbNet}}.

\input{figures/approach/network}
\input{tables/drn}
\input{tables/bottleneck}
\input{tables/aspp}
\input{tables/decoder}

\section{Loss Function}\label{section:approach-lossfunction}
We chose to use a modified weighted cross entropy loss due to the severe class imbalance.
Using the assumption that all curbs and curb cuts must be located along the perimeter of roads, we used a loss function inspired by the paper "U-Net: Convolutional Networks for Biomedical Image Segmentation," which we call Masked Cross Entropy (MCE) and defined in \eqref{eq:mce}~\cite{unet}.
The weighted cross entropy loss function was modified to penalize according to the given weights when labeling within a certain border around road classes, which we call the mask $M$.
We define road classes $\text{class}_{\text{road}}$ as all classes which can reasonably be expected to be found on roads, including road, road markings, potholes, etc.
This mask was calculated using a binary dilation on a full $b \times b$ matrix $B$ where $b$ is $0.05 \times \text{image}_{width}$ on the road class, then subtracted by the road class itself.
Thus, this can be formalized as follows:
\begin{align}
	B &= \underbrace{
			\begin{bmatrix}
				1  & \cdots & 1\\ 
				\vdots &  \ddots & \vdots\\ 
				1 &  \cdots & 1
				\end{bmatrix}}_{b \text{ columns and } b \text{ rows}} \\
	M &= \left(\text{class}_{\text{road}} \oplus B\right) - \text{class}_{\text{road}}
\end{align}
A visualization of this mask applied to a color street-level image from the Mapillary dataset results in Figure \ref{fig:approach-mask}.
\input{figures/approach/mask}

The value 0.05 was chosen empirically after looking at samples in the dataset and measuring what area around roads are typically curbs.
The road class was simply taken from the ground truth data.
Any labeling outside of $M$ by the network are then given an increased penalty, incentivizing the network to focus labeling around road edges.
We chose to multiply the penalty for areas outside $M$ by a factor of 3.
This can be seen in the following formalization of the loss function we used:
\begin{align}\label{eq:mce}
	\ell_{MCE}(y, \hat{y}) &=\sum_{m}-y_m\log(\hat{y}_m) \cdot d_m\\
	\text{with } d_m &= 
	\begin{cases}
	d_m' & \text{if } x \in M\\
	d_m' \cdot 3 & \text{if } x \notin M
	\end{cases}
\end{align}
where $d_m'$ are the user defined weights. 
This loss function operates on the assumption that curbs and curb cuts must be located adjacent to roads.
A visualization of the resulting mask $M$ can be seen in Figure \ref{fig:approach-mask}.
